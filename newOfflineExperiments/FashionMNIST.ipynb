{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5DKxMEzd0Co"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "NUM_FEATURES = 10 * 10 * 1280\n",
        "NUM_CLASSES = 10"
      ],
      "metadata": {
        "id": "ZdI00WcQesd0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransferLearningModel(tf.Module):\n",
        "  \"\"\"TF Transfer Learning model class.\"\"\"\n",
        "\n",
        "  def __init__(self, learning_rate=0.001):\n",
        "    \"\"\"Initializes a transfer learning model instance.\n",
        "    Args:\n",
        "      learning_rate: A learning rate for the optimzer.\n",
        "    \"\"\"\n",
        "    self.num_features = NUM_FEATURES\n",
        "    self.num_classes = NUM_CLASSES\n",
        "    \n",
        "    # Trainable weights and bias for softmax\n",
        "    self.ws = tf.Variable(\n",
        "        tf.zeros((self.num_features, self.num_classes)),\n",
        "        name='ws',\n",
        "        trainable=True)\n",
        "    self.bs = tf.Variable(\n",
        "        tf.zeros((1, self.num_classes)), \n",
        "        name='bs', \n",
        "        trainable=True)\n",
        "\n",
        "    # Base model\n",
        "    self.base = tf.keras.applications.MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet')\n",
        "    \n",
        "    # Add layers on top of base model\n",
        "    self.model = tf.keras.models.Sequential()\n",
        "    self.model.add(self.base)\n",
        "    self.model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    self.model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    self.model.add(tf.keras.layers.Dropout(0.5))\n",
        "    self.model.add(tf.keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32),\n",
        "    ])\n",
        "    def load(self, feature):\n",
        "      \"\"\"Generates and loads bottleneck features from the given image batch.\n",
        "       Args:\n",
        "      feature: A tensor of image feature batch to generate the bottleneck from.\n",
        "      Returns:\n",
        "       Map of the bottleneck.\n",
        "     \"\"\"\n",
        "      x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "          tf.multiply(feature, 255))\n",
        "      bottleneck = self.base(x, training=False)\n",
        "      return {'bottleneck': bottleneck}\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, NUM_FEATURES], tf.float32),\n",
        "        tf.TensorSpec([None, NUM_CLASSES], tf.float32),\n",
        "    ])\n",
        "    def train(self, bottleneck, label):\n",
        "      \"\"\"Runs one training step with the given bottleneck features and labels.\n",
        "      Args:\n",
        "      bottleneck: A tensor of bottleneck features generated from the base model.\n",
        "      label: A tensor of class labels for the given batch.\n",
        "      Returns:\n",
        "      Map of the training loss.\n",
        "      \"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "        logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
        "        prediction = tf.nn.softmax(logits)\n",
        "        loss = self.loss_fn(label, prediction)\n",
        "      gradients = tape.gradient(loss, [self.ws, self.bs])\n",
        "      self.optimizer.apply_gradients(zip(gradients, [self.ws, self.bs]))\n",
        "      result = {'loss': loss}\n",
        "      for i, grad in enumerate(gradients):\n",
        "        result['grad_{}'.format(i)] = grad\n",
        "      return result\n",
        "\n",
        "    @tf.function(input_signature=[\n",
        "        tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32)\n",
        "    ])\n",
        "    def infer(self, feature):\n",
        "      \"\"\"Invokes an inference on the given feature.\n",
        "      Args:\n",
        "      feature: A tensor of image feature batch to invoke an inference on.\n",
        "      Returns:\n",
        "       Map of the softmax output.\n",
        "      \"\"\"\n",
        "      x = tf.keras.applications.mobilenet_v2.preprocess_input(\n",
        "          tf.multiply(feature, 255))\n",
        "      bottleneck = tf.reshape(\n",
        "          self.base(x, training=False), (-1, self.num_features))\n",
        "      logits = tf.matmul(bottleneck, self.ws) + self.bs\n",
        "      prediction = tf.nn.softmax(logits)\n",
        "      return {'output': prediction}\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "    def save(self, checkpoint_path):\n",
        "          \"\"\"Saves the trainable weights to the given checkpoint file.\n",
        "          Args:\n",
        "        checkpoint_path: A file path to save the model.\n",
        "        Returns:\n",
        "        Map of the checkpoint file path.\n",
        "      \"\"\"\n",
        "    tensor_names = [self.ws.name, self.bs.name]\n",
        "    tensors_to_save = [self.ws.read_value(), self.bs.read_value()]\n",
        "    tf.raw_ops.Save(\n",
        "        filename=checkpoint_path,\n",
        "        tensor_names=tensor_names,\n",
        "        data=tensors_to_save,\n",
        "        name='save')\n",
        "    return {'checkpoint_path': checkpoint_path}\n",
        "      \n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "    def restore(self, checkpoint_path):\n",
        "      \"\"\"Restores the serialized trainable weights from the given checkpoint file.\n",
        "      Args:\n",
        "      checkpoint_path: A path to a saved checkpoint file.\n",
        "      Returns:\n",
        "      Map of restored weight and bias.\n",
        "      \"\"\"\n",
        "      restored_tensors = {}\n",
        "      restored = tf.raw_ops.Restore(\n",
        "          file_pattern=checkpoint_path,\n",
        "          tensor_name=self.ws.name,\n",
        "          dt=np.float32,\n",
        "          name='restore')\n",
        "      self.ws.assign(restored)\n",
        "      restored_tensors['ws'] = self.ws\n",
        "      restored = tf.raw_ops.Restore(\n",
        "          file_pattern=checkpoint_path,\n",
        "          tensor_name=self.bs.name,\n",
        "          dt=np.float32,\n",
        "          name='restore')\n",
        "      self.bs.assign(restored)\n",
        "      restored_tensors['bs'] = self.bs\n",
        "      return restored_tensors\n",
        "\n",
        "    @tf.function(input_signature=[])\n",
        "    def initialize_weights(self):\n",
        "      \"\"\"Initializes the weights and bias of the head model.\n",
        "      Returns:\n",
        "        Map of initialized weight and bias.\n",
        "      \"\"\"\n",
        "      self.ws.assign(tf.random.uniform((self.num_features, self.num_classes)))\n",
        "      self.bs.assign(tf.random.uniform((1, self.num_classes)))\n",
        "      return {'ws': self.ws, 'bs': self.bs}\n",
        "\n",
        "def convert_and_save(saved_model_dir='saved_model'):\n",
        "  \"\"\"Converts and saves the TFLite Transfer Learning model.\n",
        "  Args:\n",
        "      saved_model_dir: A directory path to save a converted model.\n",
        "  \"\"\"\n",
        "  model = TransferLearningModel()\n",
        "\n",
        "  tf.saved_model.save(\n",
        "      model,\n",
        "      saved_model_dir,\n",
        "      signatures={\n",
        "          'load': model.load.get_concrete_function(),\n",
        "          'train': model.train.get_concrete_function(),\n",
        "          'infer': model.infer.get_concrete_function(),\n",
        "          'save': model.save.get_concrete_function(),\n",
        "          'restore': model.restore.get_concrete_function(),\n",
        "          'initialize': model.initialize_weights.get_concrete_function(),\n",
        "      })\n",
        "\n",
        "  # Convert the model\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  converter.target_spec.supported_ops = [\n",
        "      tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
        "      tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
        "  ]\n",
        "  converter.experimental_enable_resource_variables = True\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  model_file_path = os.path.join('model.tflite')\n",
        "  with open(model_file_path, 'wb') as model_file:\n",
        "    model_file.write(tflite_model)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  convert_and_save()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "c1_js5x3e3ML",
        "outputId": "776e12d7-01e1-402d-8098-526831d5e81c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e3526f9e79ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m   \u001b[0mconvert_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-e3526f9e79ac>\u001b[0m in \u001b[0;36mconvert_and_save\u001b[0;34m(saved_model_dir)\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0msave\u001b[0m \u001b[0ma\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \"\"\"\n\u001b[0;32m--> 153\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransferLearningModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   tf.saved_model.save(\n",
            "\u001b[0;32m<ipython-input-18-e3526f9e79ac>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mtensors_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     tf.raw_ops.Save(\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensors_to_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_path' is not defined"
          ]
        }
      ]
    }
  ]
}